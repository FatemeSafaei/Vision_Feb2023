{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msUcxn5kS26P"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "2pbmqXFSS26Q",
        "outputId": "e15f8828-971f-46dc-87e5-fd6be6df0852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 1, 120)         48120     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Instantiate an empty model\n",
        "model = Sequential()\n",
        "\n",
        "# C1 Convolutional Layer\n",
        "model.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=input_shape, padding='same'))\n",
        "\n",
        "# S2 Pooling Layer\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# C3 Convolutional Layer\n",
        "model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
        "\n",
        "# S4 Pooling Layer\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# C5 Fully Connected Convolutional Layer\n",
        "model.add(Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
        "\n",
        "#Flatten the CNN output so that we can connect it with fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# FC6 Fully Connected Layer\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "\n",
        "# Output Layer with softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKQdMQkQS26Q"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo3H0_ztS26R"
      },
      "outputs": [],
      "source": [
        "# the loss function is categorical cross entropy since we have multiple classes (10)\n",
        "\n",
        "\n",
        "# compile the model by defining the loss function, optimizer, and performance metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "YwrImELsS26R",
        "outputId": "5fce7b06-5393-4c67-d375-ea30b81d9a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            " - 14s - loss: 0.2266 - accuracy: 0.9351 - val_loss: 0.0884 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.08839, saving model to model.weights.best.hdf5\n",
            "Epoch 2/20\n",
            " - 12s - loss: 0.0786 - accuracy: 0.9762 - val_loss: 0.0617 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.08839 to 0.06172, saving model to model.weights.best.hdf5\n",
            "Epoch 3/20\n",
            " - 12s - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.0492 - val_accuracy: 0.9829\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.06172 to 0.04924, saving model to model.weights.best.hdf5\n",
            "Epoch 4/20\n",
            " - 12s - loss: 0.0347 - accuracy: 0.9900 - val_loss: 0.0371 - val_accuracy: 0.9878\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.04924 to 0.03714, saving model to model.weights.best.hdf5\n",
            "Epoch 5/20\n",
            " - 13s - loss: 0.0298 - accuracy: 0.9914 - val_loss: 0.0362 - val_accuracy: 0.9882\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.03714 to 0.03624, saving model to model.weights.best.hdf5\n",
            "Epoch 6/20\n",
            " - 13s - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0335 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.03624 to 0.03353, saving model to model.weights.best.hdf5\n",
            "Epoch 7/20\n",
            " - 12s - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0307 - val_accuracy: 0.9893\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.03353 to 0.03069, saving model to model.weights.best.hdf5\n",
            "Epoch 8/20\n",
            " - 12s - loss: 0.0176 - accuracy: 0.9955 - val_loss: 0.0308 - val_accuracy: 0.9890\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.03069\n",
            "Epoch 9/20\n",
            " - 13s - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0295 - val_accuracy: 0.9894\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.03069 to 0.02953, saving model to model.weights.best.hdf5\n",
            "Epoch 10/20\n",
            " - 13s - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.0316 - val_accuracy: 0.9889\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.02953\n",
            "Epoch 11/20\n",
            " - 13s - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0297 - val_accuracy: 0.9893\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02953\n",
            "Epoch 12/20\n",
            " - 15s - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.0293 - val_accuracy: 0.9894\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.02953 to 0.02935, saving model to model.weights.best.hdf5\n",
            "Epoch 13/20\n",
            " - 13s - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0294 - val_accuracy: 0.9894\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.02935\n",
            "Epoch 14/20\n",
            " - 12s - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.0293 - val_accuracy: 0.9893\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.02935 to 0.02929, saving model to model.weights.best.hdf5\n",
            "Epoch 15/20\n",
            " - 12s - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0294 - val_accuracy: 0.9890\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.02929\n",
            "Epoch 16/20\n",
            " - 12s - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.0294 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.02929\n",
            "Epoch 17/20\n",
            " - 12s - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.0295 - val_accuracy: 0.9891\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02929\n",
            "Epoch 18/20\n",
            " - 12s - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.0295 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.02929\n",
            "Epoch 19/20\n",
            " - 12s - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.0292 - val_accuracy: 0.9895\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.02929 to 0.02924, saving model to model.weights.best.hdf5\n",
            "Epoch 20/20\n",
            " - 13s - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0293 - val_accuracy: 0.9894\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.02924\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "# set the learning rate schedule as created in the original paper\n",
        "def lr_schedule(epoch):\n",
        "    if epoch <= 2:\n",
        "        lr = 5e-4\n",
        "    elif epoch > 2 and epoch <= 5:\n",
        "        lr = 2e-4\n",
        "    elif epoch > 5 and epoch <= 9:\n",
        "        lr = 5e-5\n",
        "    else:\n",
        "        lr = 1e-5\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# set the checkpointer\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1,\n",
        "                               save_best_only=True)\n",
        "\n",
        "# train the model\n",
        "hist = model.fit(X_train, y_train, batch_size=32, epochs=20,\n",
        "          validation_data=(X_test, y_test), callbacks=[checkpointer, lr_scheduler],\n",
        "          verbose=2, shuffle=True)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}